# Ollama configuration
# Uncomment or modify the model you want to use:

# Llama 3.2 Vision (Meta's latest vision model)
OLLAMA_MODEL=llama3.2-vision:latest

# MiniCPM-V (Fast vision model with good accuracy)
# OLLAMA_MODEL=minicpm-v:latest

# LLaVA based on Llama 3 (Alternative vision model)
# OLLAMA_MODEL=llava-llama3:latest

# Server configuration (usually no need to change)
OLLAMA_HOST=http://localhost:11434 